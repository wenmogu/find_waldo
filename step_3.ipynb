{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\1920sem1\\cs4243\\cs4243-lab3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['f', 'random', 'shuffle']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv2\n",
    "import numpy as np\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as itertools \n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.spatial as scipy_spatial\n",
    "from skimage import color\n",
    "import pickle\n",
    "import sklearn\n",
    "import cyvlfeat as vlfeat\n",
    "import math\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from utils import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_files_in_dir(dir):\n",
    "    return [os.path.join(dir, img) for img in os.listdir(dir) if os.path.isfile(os.path.join(dir, img))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "range_save_dir = 'D:\\\\1920Sem1\\\\CS4243\\\\project_wx_tryout_code\\\\range'\n",
    "range_square_save_dir = 'D:\\\\1920Sem1\\\\CS4243\\\\project_wx_tryout_code\\\\range_square'\n",
    "\n",
    "wenda_square_save_dir = 'D:\\\\1920Sem1\\\\CS4243\\\\project_wx_tryout_code\\\\range_square\\\\wenda'\n",
    "wenda_test_square_save_dir = 'D:\\\\1920Sem1\\\\CS4243\\\\project_wx_tryout_code\\\\range_square\\\\wenda_test'\n",
    "detected_wendas_square_save_dir = 'D:\\\\1920Sem1\\\\CS4243\\\\project_wx_tryout_code\\\\range_square\\\\detected_wendas'\n",
    "\n",
    "wenda_waldo_square_save_dir = 'D:\\\\1920Sem1\\\\CS4243\\\\project_wx_tryout_code\\\\range_square\\\\wenda_waldo'\n",
    "rubbish_square_save_dir = 'D:\\\\1920Sem1\\\\CS4243\\\\project_wx_tryout_code\\\\range_square\\\\rubbish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "wenda_squares = [os.path.join(wenda_square_save_dir, img) for img in os.listdir(wenda_square_save_dir) if os.path.isfile(os.path.join(wenda_square_save_dir, img))]\n",
    "\n",
    "wenda_test_squares = [os.path.join(wenda_test_square_save_dir, img) for img in os.listdir(wenda_test_square_save_dir) if os.path.isfile(os.path.join(wenda_test_square_save_dir, img))]\n",
    "wenda_waldo_squares = [os.path.join(wenda_waldo_square_save_dir, img) for img in os.listdir(wenda_waldo_square_save_dir) if os.path.isfile(os.path.join(wenda_waldo_square_save_dir, img))]\n",
    "rubbish_squares = [os.path.join(rubbish_square_save_dir, img) for img in os.listdir(rubbish_square_save_dir) if os.path.isfile(os.path.join(rubbish_square_save_dir, img))]\n",
    "not_wenda_squares =  wenda_waldo_squares + rubbish_squares\n",
    "\n",
    "wenda_labels = ['wenda' for i in range(len(wenda_squares))]\n",
    "wenda_waldo_labels = ['wenda_waldo' for i in range(len(wenda_waldo_squares))]\n",
    "rubbish_labels = ['rubbish' for i in range(len(rubbish_squares))]\n",
    "not_wenda_labels = ['not_wenda' for i in range(len(wenda_waldo_squares)+len(rubbish_squares))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "53\n",
      "432\n",
      "491\n"
     ]
    }
   ],
   "source": [
    "print(len(wenda_waldo_labels))\n",
    "print(len(wenda_waldo_squares))\n",
    "print(len(wenda_test_squares))\n",
    "print(len(rubbish_squares))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_vocabulary(image_paths, vocab_size):\n",
    "    \"\"\"\n",
    "      This function will sample SIFT descriptors from the training images,\n",
    "      cluster them with kmeans, and then return the cluster centers.\n",
    "\n",
    "      Args:\n",
    "      -   image_paths: list of image paths.\n",
    "      -   vocab_size: size of vocabulary\n",
    "\n",
    "      Returns:\n",
    "      -   vocab: This is a vocab_size x d numpy array (vocabulary). Each row is a\n",
    "          cluster center / visual word\n",
    "    \"\"\"\n",
    "    # Load images from the training set. To save computation time, you don't\n",
    "    # necessarily need to sample from all images, although it would be better\n",
    "    # to do so. You can randomly sample the descriptors from each image to save\n",
    "    # memory and speed up the clustering. Or you can simply call vl_dsift with\n",
    "    # a large step size here, but a smaller step size in get_bags_of_sifts.\n",
    "    #\n",
    "    # For each loaded image, get some SIFT features. You don't have to get as\n",
    "    # many SIFT features as you will in get_bags_of_sift, because you're only\n",
    "    # trying to get a representative sample here. You can try taking 20 features\n",
    "    # per image.\n",
    "    #\n",
    "    # Once you have tens of thousands of SIFT features from many training\n",
    "    # images, cluster them with kmeans. The resulting centroids are now your\n",
    "    # visual word vocabulary.\n",
    "\n",
    "    dim = 128      # length of the SIFT descriptors that you are going to compute.\n",
    "    vocab = np.zeros((vocab_size,dim))\n",
    "    total_SIFT_features = np.zeros((20*len(image_paths), dim))\n",
    "\n",
    "    #############################################################################\n",
    "    # TODO: YOUR CODE HERE                                                      #\n",
    "    #############################################################################\n",
    "\n",
    "    # raise NotImplementedError('`build_vocabulary` function needs to be implemented')\n",
    "    descriptor_collection = np.zeros((1, dim))\n",
    "    sample_img_paths = image_paths\n",
    "#     sample_img_paths = np.random.choice(image_paths, int(len(image_paths)/10))\n",
    "\n",
    "    for i in range(len(sample_img_paths)):\n",
    "    # for i in range(10):\n",
    "        img = cv2.imread(sample_img_paths[i], 0)\n",
    "        N = 50\n",
    "        # N = 4\n",
    "        step = max(int((img.shape[0] / N)), 1)\n",
    "        size = 4\n",
    "             \n",
    "        frames, descriptors = vlfeat.sift.dsift(img, step=step, size=size)\n",
    "        # print(descriptors.shape)\n",
    "        # descriptors = descriptors[:21, :]\n",
    "        descriptor_collection = np.vstack((descriptor_collection, descriptors))\n",
    "        \n",
    "    trimmed_descriptor_collection = descriptor_collection[1:,:]\n",
    "    cluster_centers = vlfeat.kmeans.kmeans(trimmed_descriptor_collection, vocab_size)\n",
    "    vocab = cluster_centers\n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "\n",
    "    return vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing visual word vocabulary found. Computing one from training images\n",
      "vocab.pkl saved\n"
     ]
    }
   ],
   "source": [
    "vocab_filename = 'vocab.pkl'\n",
    "if not os.path.isfile(vocab_filename):\n",
    "    print('No existing visual word vocabulary found. Computing one from training images')\n",
    "    vocab_size = 100  # Larger values will work better (to a point) but be slower to compute\n",
    "    vocab = build_vocabulary(wenda_squares, vocab_size)\n",
    "    \n",
    "    with open(vocab_filename, 'wb') as f:\n",
    "        pickle.dump(vocab, f)\n",
    "        print('{:s} saved'.format(vocab_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 128)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bags_of_sifts(image_paths, vocab_filename):\n",
    "    \"\"\"\n",
    "      You will want to construct SIFT features here in the same way you\n",
    "      did in build_vocabulary() (except for possibly changing the sampling\n",
    "      rate) and then assign each local feature to its nearest cluster center\n",
    "      and build a histogram indicating how many times each cluster was used.\n",
    "      Don't forget to normalize the histogram, or else a larger image with more\n",
    "      SIFT features will look very different from a smaller version of the same\n",
    "      image.\n",
    "\n",
    "      Args:\n",
    "      -   image_paths: paths to N images\n",
    "      -   vocab_filename: Path to the precomputed vocabulary.\n",
    "              This function assumes that vocab_filename exists and contains an\n",
    "              vocab_size x 128 ndarray 'vocab' where each row is a kmeans centroid\n",
    "              or visual word. This ndarray is saved to disk rather than passed in\n",
    "              as a parameter to avoid recomputing the vocabulary every run.\n",
    "\n",
    "      Returns:\n",
    "      -   image_feats: N x d matrix, where d is the dimensionality of the\n",
    "              feature representation. In this case, d will equal the number of\n",
    "              clusters or equivalently the number of entries in each image's\n",
    "              histogram (vocab_size) below.\n",
    "    \"\"\"\n",
    "    # load vocabulary\n",
    "    with open(vocab_filename, 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "\n",
    "    # dummy features variable\n",
    "    feats = []\n",
    "\n",
    "    #############################################################################\n",
    "    # TODO: YOUR CODE HERE                                                      #\n",
    "    #############################################################################\n",
    "\n",
    "    # raise NotImplementedError('`get_bags_of_sifts` function needs to be implemented')\n",
    "    for i in range(len(image_paths)):\n",
    "    # for i in range(10):\n",
    "        img = cv2.imread(image_paths[i], 0)\n",
    "        N = 50\n",
    "        # N = 4\n",
    "        step = max(int((img.shape[0] / N)), 1)\n",
    "        size = 4\n",
    "             \n",
    "        frames, descriptors = vlfeat.sift.dsift(img, step=step, size=size)\n",
    "        D = cdist(descriptors, vocab)\n",
    "        indice_of_closest_vocab = np.argmin(D, axis=1)\n",
    "        histogram = np.zeros(vocab.shape[0])\n",
    "        for ind in indice_of_closest_vocab:\n",
    "            histogram[ind] += 1\n",
    "        normalized_histogram = normalize(histogram)\n",
    "        feats.append(normalized_histogram)\n",
    "        \n",
    "    feats = np.array(feats)\n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "\n",
    "    return feats\n",
    "\n",
    "def normalize(v):\n",
    "    norm = np.linalg.norm(v)\n",
    "    if norm == 0: \n",
    "        return v\n",
    "    return v / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nearest_neighbor_classifier(train_image_feats, train_labels, test_image_feats,\n",
    "    metric='euclidean'):\n",
    "    \"\"\"\n",
    "      Args:\n",
    "      -   train_image_feats:  N x d numpy array, where d is the dimensionality of\n",
    "              the feature representation\n",
    "      -   train_labels: N element list, where each entry is a string indicating\n",
    "              the ground truth category for each training image\n",
    "      -   test_image_feats: M x d numpy array, where d is the dimensionality of the\n",
    "              feature representation. You can assume N = M, unless you have changed\n",
    "              the starter code\n",
    "      -   metric: (optional) metric to be used for nearest neighbor.\n",
    "              Can be used to select different distance functions. The default\n",
    "              metric, 'euclidean' is fine for tiny images. 'chi2' tends to work\n",
    "              well for histograms\n",
    "\n",
    "      Returns:\n",
    "      -   test_labels: M element list, where each entry is a string indicating the\n",
    "              predicted category for each testing image\n",
    "    \"\"\"\n",
    "    test_labels = []\n",
    "\n",
    "    #############################################################################\n",
    "    # TODO: YOUR CODE HERE                                                      #\n",
    "    #############################################################################\n",
    "    D = cdist(test_image_feats, train_image_feats, metric=metric)\n",
    "    indice_of_closest_vocab = np.argmin(D, axis=1)\n",
    "\n",
    "    for ind in indice_of_closest_vocab:\n",
    "            test_labels.append(train_labels[ind])\n",
    "    # raise NotImplementedError('`nearest_neighbor_classify` function needs to be implemented')\n",
    "    \n",
    "\n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "\n",
    "    return test_labels\n",
    "\n",
    "\n",
    "def svm_classify(train_image_feats, train_labels, test_image_feats):\n",
    "    \"\"\"\n",
    "    This function will train a one-versus-one support vector machine (SVM)\n",
    "    and then use the learned classifiers to predict the category of every test image. \n",
    "\n",
    "    Args:\n",
    "    -   train_image_feats:  N x d numpy array, where d is the dimensionality of\n",
    "            the feature representation\n",
    "    -   train_labels: N element list, where each entry is a string indicating the\n",
    "            ground truth category for each training image\n",
    "    -   test_image_feats: M x d numpy array, where d is the dimensionality of the\n",
    "            feature representation. You can assume N = M, unless you have changed\n",
    "            the starter code\n",
    "    Returns:\n",
    "    -   test_labels: M element list, where each entry is a string indicating the\n",
    "            predicted category for each testing image\n",
    "    \"\"\"\n",
    "    categories = list(set(train_labels))\n",
    "    test_labels = []\n",
    "\n",
    "    #############################################################################\n",
    "    # TODO: YOUR CODE HERE                                                      #\n",
    "    #############################################################################\n",
    "    \n",
    "    # raise NotImplementedError('`svm_classify` function needs to be implemented')\n",
    "    svm = SVC(C=1000)\n",
    "    model = svm.fit(train_image_feats, train_labels)\n",
    "    test_labels = model.predict(test_image_feats)\n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "\n",
    "    return test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight(L, l):\n",
    "    if l == 0:\n",
    "        return 1 / (2 ** L)\n",
    "    else:\n",
    "        return 1 / (2 ** (L - l + 1))\n",
    "    \n",
    "def bags_of_sifts_img(img, vocab):\n",
    "    N = 10\n",
    "    step = int((img.shape[0] / N))\n",
    "    size = 4\n",
    "\n",
    "    frames, descriptors = vlfeat.sift.dsift(img, step=step, size=size)\n",
    "    D = cdist(descriptors, vocab)\n",
    "    indice_of_closest_vocab = np.argmin(D, axis=1)\n",
    "    histogram = np.zeros(vocab.shape[0])\n",
    "    for ind in indice_of_closest_vocab:\n",
    "        histogram[ind] += 1\n",
    "    return histogram\n",
    "    \n",
    "def bags_of_sifts_spm_individual(img, vocab, depth, current_level):\n",
    "    if depth == current_level:\n",
    "        return bags_of_sifts_img(img, vocab) * weight(depth, current_level)\n",
    "    else:\n",
    "        img_width = img.shape[1]\n",
    "        img_height = img.shape[0]\n",
    "        img1 = img[0:int(img_height/2), 0:int(img_width/2)]\n",
    "        img2 = img[0:int(img_height/2), int(img_width/2):]\n",
    "        img3 = img[int(img_height/2):, 0:int(img_width/2)]\n",
    "        img4 = img[int(img_height/2):, int(img_width/2):]\n",
    "        \n",
    "        img_hist = bags_of_sifts_img(img, vocab) * weight(depth, current_level)\n",
    "        \n",
    "        img1_hist = bags_of_sifts_spm_individual(img1, vocab, depth, current_level+1)\n",
    "        img2_hist = bags_of_sifts_spm_individual(img2, vocab, depth, current_level+1)\n",
    "        img3_hist = bags_of_sifts_spm_individual(img3, vocab, depth, current_level+1)                      \n",
    "        img4_hist = bags_of_sifts_spm_individual(img4, vocab, depth, current_level+1)\n",
    "        return np.concatenate((img_hist, img1_hist, img2_hist, img3_hist, img4_hist), axis=None)\n",
    "        \n",
    "def bags_of_sifts_spm(image_paths, vocab_filename, depth):\n",
    "    \"\"\"\n",
    "    Bags of sifts with spatial pyramid matching.\n",
    "\n",
    "    :param image_paths: paths to N images\n",
    "    :param vocab_filename: Path to the precomputed vocabulary.\n",
    "          This function assumes that vocab_filename exists and contains an\n",
    "          vocab_size x 128 ndarray 'vocab' where each row is a kmeans centroid\n",
    "          or visual word. This ndarray is saved to disk rather than passed in\n",
    "          as a parameter to avoid recomputing the vocabulary every run.\n",
    "    :param depth: Depth L of spatial pyramid. Divide images and compute (sum)\n",
    "          bags-of-sifts for all image partitions for all pyramid levels.\n",
    "          Refer to the explanation in the notebook, tutorial slide and the \n",
    "          original paper (Lazebnik et al. 2006.) for more details.\n",
    "\n",
    "    :return image_feats: N x d matrix, where d is the dimensionality of the\n",
    "          feature representation. In this case, d will equal the number of\n",
    "          clusters (vocab_size) times the number of regions in all pyramid levels,\n",
    "          which is 21 (1+4+16) in this specific case.\n",
    "    \"\"\"\n",
    "    with open(vocab_filename, 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "    \n",
    "    vocab_size = vocab.shape[0]\n",
    "    feats = []\n",
    "\n",
    "    #############################################################################\n",
    "    # TODO: YOUR CODE HERE                                                      #\n",
    "    #############################################################################\n",
    "\n",
    "    # raise NotImplementedError('`get_bags_of_sifts` function needs to be implemented')\n",
    "    # image_paths = image_paths[:1]\n",
    "    depth = depth - 1\n",
    "    for path in image_paths:\n",
    "        img = load_image_gray(path)\n",
    "        feats.append(bags_of_sifts_spm_individual(img, vocab, depth, 0))\n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "    feats = np.array(feats)\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\1920sem1\\cs4243\\cs4243-lab3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "test_feats = bags_of_sifts(wenda_test_squares, 'vocab.pkl')\n",
    "\n",
    "random_index = [i for i in range(400)]\n",
    "if (len(rubbish_labels) > 400):\n",
    "    random_index = random.sample(range(len(rubbish_labels)), 400)\n",
    "    \n",
    "train_labels = wenda_labels + [rubbish_labels[i] for i in random_index] \n",
    "train_imgs = wenda_squares + [rubbish_squares[i] for i in random_index] \n",
    "\n",
    "train_feats = bags_of_sifts(train_imgs, 'vocab.pkl')\n",
    "test_labels = svm_classify(train_feats, train_labels, test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_wendas = [wenda_test_squares[i] for i in range(len(test_labels)) if test_labels[i]=='wenda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "detected_wendas_square_save_dir = 'D:\\\\1920Sem1\\\\CS4243\\\\project_wx_tryout_code\\\\range_square\\\\detected_wendas'\n",
    "\n",
    "for f in all_files_in_dir(detected_wendas_square_save_dir):\n",
    "    os.remove(f)\n",
    "    \n",
    "count = 0\n",
    "for detected_wenda in detected_wendas:\n",
    "    copyfile(detected_wenda, os.path.join(detected_wendas_square_save_dir, str(count)+\".png\"))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wenda_test_squares = all_files_in_dir(detected_wendas_square_save_dir)\n",
    "wenda_test_labels = [\"wenda\" for i in range(len(wenda_test_squares))]\n",
    "wenda_waldo_squares = all_files_in_dir(wenda_waldo_square_save_dir)\n",
    "wenda_waldo_labels = [\"waldo\" for i in range(len(wenda_waldo_squares))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\1920sem1\\cs4243\\cs4243-lab3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "test_feats = bags_of_sifts(wenda_test_squares, 'vocab.pkl')\n",
    "\n",
    "# random_index = random.sample(range(len(rubbish_labels)), 300)\n",
    "# random_index_waldo = random.sample(range(len(wenda_waldo_labels)), 20)\n",
    "train_labels = wenda_labels + wenda_waldo_labels\n",
    "train_imgs = wenda_squares + wenda_waldo_squares\n",
    "print(len(train_labels))\n",
    "print(len(train_imgs))\n",
    "# train_labels =  ['rubbish' for i in range(6)] + ['wenda'] + ['rubbish' for i in range(7, 15)]+ [rubbish_labels[i] for i in random_index]\n",
    "# train_imgs = all_files_in_dir(detected_wendas_square_save_dir) + [rubbish_squares[i] for i in random_index]\n",
    "train_feats = bags_of_sifts(train_imgs, 'vocab.pkl')\n",
    "test_labels = svm_classify(train_feats, train_labels, test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detected_wendas = [wenda_test_squares[i] for i in range(len(test_labels)) if test_labels[i]=='wenda']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "detected_wendas_square_save_dir = 'D:\\\\1920Sem1\\\\CS4243\\\\project_wx_tryout_code\\\\range_square\\\\detected_wendas_clean'\n",
    "\n",
    "for f in all_files_in_dir(detected_wendas_square_save_dir):\n",
    "    os.remove(f)\n",
    "    \n",
    "count = 0\n",
    "for detected_wenda in detected_wendas:\n",
    "    copyfile(detected_wenda, os.path.join(detected_wendas_square_save_dir, str(count)+\".png\"))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
