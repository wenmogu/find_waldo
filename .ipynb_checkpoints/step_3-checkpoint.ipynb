{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\1920sem1\\cs4243\\cs4243-lab3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['shuffle']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv2\n",
    "import numpy as np\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as itertools \n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.spatial as scipy_spatial\n",
    "from skimage import color\n",
    "import pickle\n",
    "import sklearn\n",
    "import cyvlfeat as vlfeat\n",
    "import math\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "range_save_dir = 'D:\\\\1920Sem1\\\\CS4243\\\\project_wx_tryout_code\\\\range'\n",
    "range_square_save_dir = 'D:\\\\1920Sem1\\\\CS4243\\\\project_wx_tryout_code\\\\range_square'\n",
    "\n",
    "wenda_square_save_dir = 'D:\\\\1920Sem1\\\\CS4243\\\\project_wx_tryout_code\\\\range_square\\\\wenda'\n",
    "wenda_test_square_save_dir = 'D:\\\\1920Sem1\\\\CS4243\\\\project_wx_tryout_code\\\\range_square\\\\wenda_test'\n",
    "\n",
    "wenda_waldo_square_save_dir = 'D:\\\\1920Sem1\\\\CS4243\\\\project_wx_tryout_code\\\\range_square\\\\wenda_waldo'\n",
    "rubbish_square_save_dir = 'D:\\\\1920Sem1\\\\CS4243\\\\project_wx_tryout_code\\\\range_square\\\\rubbish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wenda_squares = [os.path.join(wenda_square_save_dir, img) for img in os.listdir(wenda_square_save_dir) if os.path.isfile(os.path.join(wenda_square_save_dir, img))]\n",
    "wenda_test_squares = [os.path.join(wenda_test_square_save_dir, img) for img in os.listdir(wenda_test_square_save_dir) if os.path.isfile(os.path.join(wenda_test_square_save_dir, img))]\n",
    "wenda_waldo_squares = [os.path.join(wenda_waldo_square_save_dir, img) for img in os.listdir(wenda_waldo_square_save_dir) if os.path.isfile(os.path.join(wenda_waldo_square_save_dir, img))]\n",
    "rubbish_squares = [os.path.join(rubbish_square_save_dir, img) for img in os.listdir(rubbish_square_save_dir) if os.path.isfile(os.path.join(rubbish_square_save_dir, img))]\n",
    "\n",
    "wenda_labels = ['wenda' for i in range(len(wenda_squares))]\n",
    "wenda_labels = ['not_wenda' for i in range(len(wenda_waldo_squares)+len(rubbish_squares))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_vocabulary(image_paths, vocab_size):\n",
    "    \"\"\"\n",
    "      This function will sample SIFT descriptors from the training images,\n",
    "      cluster them with kmeans, and then return the cluster centers.\n",
    "\n",
    "      Args:\n",
    "      -   image_paths: list of image paths.\n",
    "      -   vocab_size: size of vocabulary\n",
    "\n",
    "      Returns:\n",
    "      -   vocab: This is a vocab_size x d numpy array (vocabulary). Each row is a\n",
    "          cluster center / visual word\n",
    "    \"\"\"\n",
    "    # Load images from the training set. To save computation time, you don't\n",
    "    # necessarily need to sample from all images, although it would be better\n",
    "    # to do so. You can randomly sample the descriptors from each image to save\n",
    "    # memory and speed up the clustering. Or you can simply call vl_dsift with\n",
    "    # a large step size here, but a smaller step size in get_bags_of_sifts.\n",
    "    #\n",
    "    # For each loaded image, get some SIFT features. You don't have to get as\n",
    "    # many SIFT features as you will in get_bags_of_sift, because you're only\n",
    "    # trying to get a representative sample here. You can try taking 20 features\n",
    "    # per image.\n",
    "    #\n",
    "    # Once you have tens of thousands of SIFT features from many training\n",
    "    # images, cluster them with kmeans. The resulting centroids are now your\n",
    "    # visual word vocabulary.\n",
    "\n",
    "    dim = 128      # length of the SIFT descriptors that you are going to compute.\n",
    "    vocab = np.zeros((vocab_size,dim))\n",
    "    total_SIFT_features = np.zeros((20*len(image_paths), dim))\n",
    "\n",
    "    #############################################################################\n",
    "    # TODO: YOUR CODE HERE                                                      #\n",
    "    #############################################################################\n",
    "\n",
    "    # raise NotImplementedError('`build_vocabulary` function needs to be implemented')\n",
    "    descriptor_collection = np.zeros((1, dim))\n",
    "    sample_img_paths = image_paths\n",
    "#     sample_img_paths = np.random.choice(image_paths, int(len(image_paths)/10))\n",
    "\n",
    "    for i in range(len(sample_img_paths)):\n",
    "    # for i in range(10):\n",
    "        img = cv2.imread(sample_img_paths[i], 0)\n",
    "        N = 50\n",
    "        # N = 4\n",
    "        step = max(int((img.shape[0] / N)), 1)\n",
    "        size = 4\n",
    "             \n",
    "        frames, descriptors = vlfeat.sift.dsift(img, step=step, size=size)\n",
    "        # print(descriptors.shape)\n",
    "        # descriptors = descriptors[:21, :]\n",
    "        descriptor_collection = np.vstack((descriptor_collection, descriptors))\n",
    "        \n",
    "    trimmed_descriptor_collection = descriptor_collection[1:,:]\n",
    "    cluster_centers = vlfeat.kmeans.kmeans(trimmed_descriptor_collection, vocab_size)\n",
    "    vocab = cluster_centers\n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "\n",
    "    return vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing visual word vocabulary found. Computing one from training images\n",
      "vocab.pkl saved\n"
     ]
    }
   ],
   "source": [
    "vocab_filename = 'vocab.pkl'\n",
    "if not os.path.isfile(vocab_filename):\n",
    "    print('No existing visual word vocabulary found. Computing one from training images')\n",
    "    vocab_size = 20  # Larger values will work better (to a point) but be slower to compute\n",
    "    vocab = build_vocabulary(wenda_squares, vocab_size)\n",
    "    \n",
    "    with open(vocab_filename, 'wb') as f:\n",
    "        pickle.dump(vocab, f)\n",
    "        print('{:s} saved'.format(vocab_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 128)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bags_of_sifts(image_paths, vocab_filename):\n",
    "    \"\"\"\n",
    "      You will want to construct SIFT features here in the same way you\n",
    "      did in build_vocabulary() (except for possibly changing the sampling\n",
    "      rate) and then assign each local feature to its nearest cluster center\n",
    "      and build a histogram indicating how many times each cluster was used.\n",
    "      Don't forget to normalize the histogram, or else a larger image with more\n",
    "      SIFT features will look very different from a smaller version of the same\n",
    "      image.\n",
    "\n",
    "      Args:\n",
    "      -   image_paths: paths to N images\n",
    "      -   vocab_filename: Path to the precomputed vocabulary.\n",
    "              This function assumes that vocab_filename exists and contains an\n",
    "              vocab_size x 128 ndarray 'vocab' where each row is a kmeans centroid\n",
    "              or visual word. This ndarray is saved to disk rather than passed in\n",
    "              as a parameter to avoid recomputing the vocabulary every run.\n",
    "\n",
    "      Returns:\n",
    "      -   image_feats: N x d matrix, where d is the dimensionality of the\n",
    "              feature representation. In this case, d will equal the number of\n",
    "              clusters or equivalently the number of entries in each image's\n",
    "              histogram (vocab_size) below.\n",
    "    \"\"\"\n",
    "    # load vocabulary\n",
    "    with open(vocab_filename, 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "\n",
    "    # dummy features variable\n",
    "    feats = []\n",
    "\n",
    "    #############################################################################\n",
    "    # TODO: YOUR CODE HERE                                                      #\n",
    "    #############################################################################\n",
    "\n",
    "    # raise NotImplementedError('`get_bags_of_sifts` function needs to be implemented')\n",
    "    for i in range(len(image_paths)):\n",
    "    # for i in range(10):\n",
    "        img = cv2.imread(image_paths[i], 0)\n",
    "        N = 50\n",
    "        # N = 4\n",
    "        step = max(int((img.shape[0] / N)), 1)\n",
    "        size = 4\n",
    "             \n",
    "        frames, descriptors = vlfeat.sift.dsift(img, step=step, size=size)\n",
    "        D = cdist(descriptors, vocab)\n",
    "        indice_of_closest_vocab = np.argmin(D, axis=1)\n",
    "        histogram = np.zeros(vocab.shape[0])\n",
    "        for ind in indice_of_closest_vocab:\n",
    "            histogram[ind] += 1\n",
    "        normalized_histogram = normalize(histogram)\n",
    "        feats.append(normalized_histogram)\n",
    "        \n",
    "    feats = np.array(feats)\n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "\n",
    "    return feats\n",
    "\n",
    "def normalize(v):\n",
    "    norm = np.linalg.norm(v)\n",
    "    if norm == 0: \n",
    "        return v\n",
    "    return v / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nearest_neighbor_classifier(train_image_feats, train_labels, test_image_feats,\n",
    "    metric='euclidean'):\n",
    "    \"\"\"\n",
    "      Args:\n",
    "      -   train_image_feats:  N x d numpy array, where d is the dimensionality of\n",
    "              the feature representation\n",
    "      -   train_labels: N element list, where each entry is a string indicating\n",
    "              the ground truth category for each training image\n",
    "      -   test_image_feats: M x d numpy array, where d is the dimensionality of the\n",
    "              feature representation. You can assume N = M, unless you have changed\n",
    "              the starter code\n",
    "      -   metric: (optional) metric to be used for nearest neighbor.\n",
    "              Can be used to select different distance functions. The default\n",
    "              metric, 'euclidean' is fine for tiny images. 'chi2' tends to work\n",
    "              well for histograms\n",
    "\n",
    "      Returns:\n",
    "      -   test_labels: M element list, where each entry is a string indicating the\n",
    "              predicted category for each testing image\n",
    "    \"\"\"\n",
    "    test_labels = []\n",
    "\n",
    "    #############################################################################\n",
    "    # TODO: YOUR CODE HERE                                                      #\n",
    "    #############################################################################\n",
    "    D = cdist(test_image_feats, train_image_feats, metric=metric)\n",
    "    indice_of_closest_vocab = np.argmin(D, axis=1)\n",
    "\n",
    "    for ind in indice_of_closest_vocab:\n",
    "            test_labels.append(train_labels[ind])\n",
    "    # raise NotImplementedError('`nearest_neighbor_classify` function needs to be implemented')\n",
    "    \n",
    "\n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "\n",
    "    return test_labels\n",
    "\n",
    "\n",
    "def svm_classify(train_image_feats, train_labels, test_image_feats):\n",
    "    \"\"\"\n",
    "    This function will train a one-versus-one support vector machine (SVM)\n",
    "    and then use the learned classifiers to predict the category of every test image. \n",
    "\n",
    "    Args:\n",
    "    -   train_image_feats:  N x d numpy array, where d is the dimensionality of\n",
    "            the feature representation\n",
    "    -   train_labels: N element list, where each entry is a string indicating the\n",
    "            ground truth category for each training image\n",
    "    -   test_image_feats: M x d numpy array, where d is the dimensionality of the\n",
    "            feature representation. You can assume N = M, unless you have changed\n",
    "            the starter code\n",
    "    Returns:\n",
    "    -   test_labels: M element list, where each entry is a string indicating the\n",
    "            predicted category for each testing image\n",
    "    \"\"\"\n",
    "    categories = list(set(train_labels))\n",
    "    test_labels = []\n",
    "\n",
    "    #############################################################################\n",
    "    # TODO: YOUR CODE HERE                                                      #\n",
    "    #############################################################################\n",
    "    \n",
    "    # raise NotImplementedError('`svm_classify` function needs to be implemented')\n",
    "    svm = SVC(C=1000)\n",
    "    model = svm.fit(train_image_feats, train_labels)\n",
    "    test_labels = model.predict(test_image_feats)\n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "\n",
    "    return test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_feats = bags_of_sifts(wenda_test_squares, 'vocab.pkl')\n",
    "\n",
    "train_labels = \n",
    "train_imgs = wenda_squares + wenda_waldo_squares + rubbish_squares\n",
    "train_feats = bags_of_sifts(train_imgs, 'vocab.pkl')\n",
    "test_labels = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
