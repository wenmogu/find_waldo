{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\1920sem1\\cs4243\\cs4243-lab3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv2\n",
    "import numpy as np\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as itertools \n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.spatial as scipy_spatial\n",
    "from skimage import color\n",
    "import pickle\n",
    "import sklearn\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_save_dir = 'D:\\\\1920Sem1\\\\CS4243\\\\project_wx_tryout_code\\\\rectangles'\n",
    "\n",
    "image_dir = \"D:\\\\1920Sem1\\CS4243\\project\\CS4243-Project\\datasets\\JPEGImages\"\n",
    "images = [os.path.join(image_dir, img) for img in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, img))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_input_img(img_0):\n",
    "    hsv = cv2.cvtColor(img_0, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    lower_red = np.array([110,80,80])\n",
    "    upper_red = np.array([160,255,255])\n",
    "    mask_red_only = cv2.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "    lower_white = np.array([0,0,255])\n",
    "    upper_white = np.array([255,255,255])\n",
    "    mask_white_only = cv2.inRange(hsv, lower_white, upper_white)\n",
    "    \n",
    "    # attach a column of row number to the masks\n",
    "    index_array = np.flip(np.arange(mask_red_only.shape[1]))\n",
    "\n",
    "    stacked_red = np.vstack((index_array, mask_red_only))\n",
    "    stacked_red_white = np.vstack((stacked_red, mask_white_only))\n",
    "\n",
    "    red_mask_rot = np.rot90(stacked_red)\n",
    "    red_white_mask_rot = np.rot90(stacked_red_white)\n",
    "    \n",
    "    return red_white_mask_rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_suspected_waldo_stripe_region_for_col(red_white_mask_col, ratio_range=(1/2, 2), white_pixel_threshold=0.15):\n",
    "    col_index = red_white_mask_col[0]\n",
    "    red_mask_col = red_white_mask_col[1:int((len(red_white_mask_col)-1)/2+1)]\n",
    "    white_mask_col = red_white_mask_col[int((len(red_white_mask_col)-1)/2+1):]\n",
    "    assert red_mask_col.shape == white_mask_col.shape, \"the mask column inputs for white and red masks are of different shapes:\" + str(red_mask_col.shape) + \"; \" + str(white_mask_col.shape)\n",
    "    \n",
    "    \n",
    "    white_mask_col = white_mask_col[1:]\n",
    "    \n",
    "    new_red_mask_col = np.zeros(len(red_mask_col))\n",
    "    new_red_mask_col[red_mask_col == 255] = 1\n",
    "    new_red_mask_col[red_mask_col == 0] = -1\n",
    "    \n",
    "    new_white_mask_col = np.zeros(len(white_mask_col))\n",
    "    new_white_mask_col[white_mask_col == 255] = 1\n",
    "    new_white_mask_col[white_mask_col == 0] = 0\n",
    "\n",
    "    streak_array = get_streak_len_array_with_approx(new_red_mask_col, 0)\n",
    "    ratio_array = np.array([abs(streak_array[i]) / abs(streak_array[i + 1]) for i in range(len(streak_array) - 1)])\n",
    "    accepted_ratio_indice, = np.where(np.logical_and(ratio_array > ratio_range[0], ratio_array < ratio_range[1]))\n",
    "    is_accepted_ratio_indice_continuous, lst_of_start_and_end = is_indice_continuous(accepted_ratio_indice)\n",
    "\n",
    "    revised_lst_of_start_and_end = []\n",
    "\n",
    "    if is_accepted_ratio_indice_continuous:\n",
    "        # then check if the negative pixels are white pixels\n",
    "        for start, end in lst_of_start_and_end:\n",
    "            is_region_start_with_red = streak_array[start+2] > 0\n",
    "            offset = 0\n",
    "            if is_region_start_with_red:\n",
    "                offset = 1\n",
    "            \n",
    "            total_number_of_white_pixels = 0\n",
    "            total_number_of_non_red_pixels = 0\n",
    "#             region = [np.sum(np.abs(streak_array[:accepted_ratio_indice[start]])), np.sum(np.abs(streak_array[:accepted_ratio_indice[end-1]+1]))]\n",
    "#             print(\"start, end: \" + str(region[0]) + \", \" + str(region[1]))\n",
    "\n",
    "            while start + offset < end:\n",
    "                supposedly_white_pixel_region = [np.sum(np.abs(streak_array[:accepted_ratio_indice[start + offset]])), np.sum(np.abs(streak_array[:accepted_ratio_indice[start + offset]+1]))]\n",
    "\n",
    "                number_of_white_pixels = np.sum(new_white_mask_col[int(supposedly_white_pixel_region[0]) : int(supposedly_white_pixel_region[1])])\n",
    "                number_of_non_red_pixels = supposedly_white_pixel_region[1] - supposedly_white_pixel_region[0]\n",
    "\n",
    "                total_number_of_white_pixels += number_of_white_pixels\n",
    "                total_number_of_non_red_pixels += number_of_non_red_pixels\n",
    "                offset += 2\n",
    "\n",
    "            if total_number_of_white_pixels / total_number_of_non_red_pixels > white_pixel_threshold:\n",
    "                revised_lst_of_start_and_end.append((start, end))\n",
    "        \n",
    "        if len(revised_lst_of_start_and_end) == 0:\n",
    "            empty_terms = np.array(list(itertools.repeat([int(False), col_index, -1, -1, 0, 0], 20)))\n",
    "            return empty_terms\n",
    "        stripe_region = [[int(True), \\\n",
    "                          col_index, \\\n",
    "                          np.sum(np.abs(streak_array[:accepted_ratio_indice[start]])), \\\n",
    "                          np.sum(np.abs(streak_array[:accepted_ratio_indice[end-1]+1])), \\\n",
    "                          int(end - start), \\\n",
    "                          (np.sum(np.abs(streak_array[:accepted_ratio_indice[end-1]+1])) - np.sum(np.abs(streak_array[:accepted_ratio_indice[start]]))) / int(end - start)] \\\n",
    "                         for start, end in revised_lst_of_start_and_end]\n",
    "        # from here examine the percentage of white pixels in the region\n",
    "        # if there are white pixels dominating the negative pixels, then it is stripes\n",
    "        # return (1, col_number, start_of_stripe_region, end_of_stripe_region, number_of_stripes, average_width_of_stripes)        \n",
    "        how_many_more_terms = 20 - len(stripe_region)\n",
    "        additional_terms = np.array(list(itertools.repeat([int(False), col_index, -1, -1, 0, 0], how_many_more_terms)))\n",
    "        return np.vstack((stripe_region, additional_terms))    \n",
    "\n",
    "    empty_terms = np.array(list(itertools.repeat([int(False), col_index, -1, -1, 0, 0], 20)))\n",
    "    return empty_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_streak_len_array_with_approx(unit_lst, threshold):\n",
    "    # in the unit_lst, 1 represents the superior pixel value, -1 is the inferior pixel value\n",
    "    # the superior pixel value is the one that is well captured in color distillation \n",
    "    # in our case e.g. red is the superior pixel value because it is well captured \n",
    "    # and white is the inferior pixel value because it might be noise\n",
    "    # we want to restore the shape outlined by the superior pixel value\n",
    "    # hence we need to minimize the disturbannce by the inferior pixel value\n",
    "    # hence we need to remove the 'sparse' inferior pixel value located within the streaks of superior pixel values\n",
    "    # the definition of sparse is given by the threshold\n",
    "    previous = 0\n",
    "    streak_len_array = []\n",
    "    streak_len = 0\n",
    "    fast_forward_count = 0\n",
    "    for i in range(len(unit_lst)):\n",
    "        if i == 0:\n",
    "            previous = unit_lst[i]\n",
    "            \n",
    "        if fast_forward_count > 0:\n",
    "            fast_forward_count -= 1\n",
    "            if i == len(unit_lst) - 1:\n",
    "                streak_len_array.append(streak_len)\n",
    "            continue\n",
    "        \n",
    "        if previous == unit_lst[i]:\n",
    "            cur_streak_len = streak_len\n",
    "            streak_len += unit_lst[i]\n",
    "            if i == len(unit_lst) - 1:\n",
    "                streak_len_array.append(streak_len)\n",
    "            previous = unit_lst[i]\n",
    "        else:\n",
    "            if streak_len > 0:\n",
    "                # superior pixel streak ending\n",
    "                cur_streak_len = streak_len\n",
    "                # we need to look ahead the threshold number of pixels to see if theres any superior pixel\n",
    "                next_few_number = min(threshold, len(unit_lst) - 1 - i)\n",
    "                next_few_pixels = unit_lst[i : i+1+next_few_number]\n",
    "                # if there is we will continue the superior pixel streak from there\n",
    "                indice_of_next_superior_pixel, = np.where(next_few_pixels == 1)\n",
    "                if len(indice_of_next_superior_pixel) != 0:\n",
    "                    next_superior = max(indice_of_next_superior_pixel)\n",
    "                    streak_len += 1 + next_superior\n",
    "                    fast_forward_count = next_superior\n",
    "                    previous = abs(unit_lst[i])\n",
    "                # if not we end the superior pixel streak here and start a new inferior pixel streak\n",
    "                else:\n",
    "                    streak_len_array.append(cur_streak_len)\n",
    "                    streak_len = 0\n",
    "                    streak_len += unit_lst[i]\n",
    "                    previous = unit_lst[i]\n",
    "            elif streak_len < 0:\n",
    "                # inferior pixel streak ending\n",
    "                # we will start a new superior pixel streak\n",
    "                streak_len_array.append(streak_len)\n",
    "                streak_len = 0\n",
    "                streak_len += unit_lst[i]\n",
    "                previous = unit_lst[i]\n",
    "            \n",
    "    return streak_len_array\n",
    "\n",
    "def get_streak_len_array(unit_lst):\n",
    "    previous = 0\n",
    "    streak_len_array = []\n",
    "    streak_len = 0\n",
    "    for i in range(len(unit_lst)):\n",
    "        if i == 0:\n",
    "            previous = unit_lst[i]\n",
    "        \n",
    "        if previous == unit_lst[i]:\n",
    "            streak_len += unit_lst[i]\n",
    "            if i == len(unit_lst) - 1:\n",
    "                streak_len_array.append(streak_len)\n",
    "        else:\n",
    "            streak_len_array.append(streak_len)\n",
    "            streak_len = 0\n",
    "            \n",
    "        previous = unit_lst[i]\n",
    "        \n",
    "    return streak_len_array\n",
    "\n",
    "\n",
    "# Method: Given a 1D array, find the starting position and the ending position of an arithmatic sequence with the next equal to 1+previous. The sequence must contain no less than 3 numbers.\n",
    "# Input: a 1D array of integers\n",
    "# Output: a tuple in the form of (Boolean, list). The boolean is True when there is at least one sequence. The list consists of tuples (starting_position_of_sequence_inclusive, ending_position_of_sequence_exclusive)\n",
    "def is_indice_continuous(lst_of_indice):\n",
    "    # right now the number of stripes accepted is 3\n",
    "    is_continuous = False\n",
    "    continuous_count = 0\n",
    "    prev = -1\n",
    "    start_index = -1\n",
    "    lst_of_start_and_end = []\n",
    "    for i in range(len(lst_of_indice)):\n",
    "        if i == 0:\n",
    "            prev = lst_of_indice[i]\n",
    "            start_index = i\n",
    "            continuous_count = 1\n",
    "            continue\n",
    "            \n",
    "        if lst_of_indice[i] - prev == 1:\n",
    "            # the streak continues\n",
    "            continuous_count += 1\n",
    "        else:\n",
    "            # the streak ends\n",
    "            if continuous_count >= 3:\n",
    "                lst_of_start_and_end.append((start_index, i))\n",
    "                is_continuous = True\n",
    "\n",
    "            continuous_count = 1\n",
    "            start_index = i\n",
    "            \n",
    "        if i == len(lst_of_indice) - 1:\n",
    "            if start_index != -1 and continuous_count >= 3:\n",
    "                lst_of_start_and_end.append((start_index, i))\n",
    "                is_continuous = True\n",
    "        \n",
    "        prev = lst_of_indice[i]\n",
    "        \n",
    "    return (is_continuous, lst_of_start_and_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')\n",
    "\n",
    "def convert_rot90_col_no_to_original_col_no(rot90_image, col_no):\n",
    "    return rot90_image.shape[0] - col_no\n",
    "\n",
    "def convert_original_col_no_to_rot90_col_no(image, col_no):\n",
    "    return image.shape[1] - col_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_able_to_combine(row1, row2, confidence_area_overlap_ratio_threshold):\n",
    "    row1_width = row1[3] - row1[2]\n",
    "    row1_height = row1[5] - row1[4]\n",
    "    row2_width = row2[3] - row2[2]\n",
    "    row2_height = row2[5] - row2[4]\n",
    "    \n",
    "    bbox1 = (row1[2], row1[4], row1_width, row1_height)\n",
    "    bbox2 = (row2[2], row2[4], row2_width, row2_height)\n",
    "    \n",
    "    iou = IoU(bbox1, bbox2)\n",
    "    \n",
    "    if (iou >= confidence_area_overlap_ratio_threshold):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def IoU(bbox1, bbox2):\n",
    "    \"\"\" Compute IoU of two bounding boxes\n",
    "\n",
    "    Args:\n",
    "        bbox1 - 4-tuple (x, y, w, h) where (x, y) is the top left corner of\n",
    "            the bounding box, and (w, h) are width and height of the box.\n",
    "        bbox2 - 4-tuple (x, y, w, h) where (x, y) is the top left corner of\n",
    "            the bounding box, and (w, h) are width and height of the box.\n",
    "    Returns:\n",
    "        score - IoU score\n",
    "    \"\"\"\n",
    "    x1, y1, w1, h1 = bbox1\n",
    "    x2, y2, w2, h2 = bbox2\n",
    "    score = 0\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    x_left = max(x1, x2)\n",
    "    y_top = max(y1, y2)\n",
    "    x_right = min(x1+w1, x2+w2)\n",
    "    y_bottom = min(y1+h1, y2+h2)\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    area1 = w1 * h1\n",
    "    area2 = w2 * h2\n",
    "    score = intersection_area / float(area1 + area2 - intersection_area)\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return score\n",
    "\n",
    "    \n",
    "def merge_rows(data, row_1_index, row_2_index):\n",
    "#     ['col_no_original', 'stripe_centre_for_each_col',\n",
    "#        'col_confidence_interval_start', 'col_confidence_interval_end',\n",
    "#        'row_confidence_interval_start', 'row_confidence_interval_end']\n",
    "    row_1 = data[row_1_index][:-1]\n",
    "    row_2 = data[row_2_index][:-1]\n",
    "    row_1_no_of_times_combined = data[row_1_index][-1]\n",
    "    row_2_no_of_times_combined = data[row_2_index][-1]\n",
    "    total_no_of_times_combined = row_2_no_of_times_combined + row_1_no_of_times_combined\n",
    "    row_3 = np.add(row_1*row_1_no_of_times_combined, row_2*row_2_no_of_times_combined) / total_no_of_times_combined\n",
    "    \n",
    "    row_3 = np.append(row_3, total_no_of_times_combined)\n",
    "#     new_data = np.append(data, row_3.reshape((1, len(row_3))), axis=0)\n",
    "#     new_data = np.delete(new_data, [row_1_index, row_2_index], axis=0)\n",
    "    data[row_1_index] = row_3\n",
    "    new_data = np.delete(data, [row_2_index], axis=0)\n",
    "    return new_data\n",
    "\n",
    "def combine_to_region(df, confidence_area_overlap_ratio_threshold):\n",
    "    if (\"no_of_times_combined\" not in df.columns):\n",
    "        df[\"no_of_times_combined\"] = 1\n",
    "        \n",
    "    all_data = df[:].to_numpy()\n",
    "    \n",
    "    data = np.copy(all_data)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    while (True):\n",
    "        if count >= len(data) - 1:\n",
    "            return pd.DataFrame(data=data, columns=df.columns)\n",
    "        else:\n",
    "            this_row = data[count]\n",
    "            rest_rows = np.delete(data, count, axis=0)\n",
    "            this_vector = this_row[:2]\n",
    "            rest_vectors = rest_rows[:, :2]\n",
    "            # find the vector with the shortest distance\n",
    "            dist = scipy_spatial.distance.cdist(this_vector.reshape((1,2)), rest_vectors)\n",
    "            closest_vector_index = np.argmin(dist)\n",
    "            closest_row = rest_rows[closest_vector_index]\n",
    "            # if can combine, then merge, and the index will take the one of the smaller index, recurse.\n",
    "            can_combine = is_able_to_combine(this_row, closest_row, confidence_area_overlap_ratio_threshold)\n",
    "            if can_combine:\n",
    "                # merge, and the index will take the one of the smaller index, recurse.\n",
    "                if count <= closest_vector_index:\n",
    "                    closest_vector_index += 1\n",
    "                new_data = merge_rows(data, count, closest_vector_index)\n",
    "                count = 0\n",
    "                data = new_data\n",
    "            else:\n",
    "                # count++, recurse.\n",
    "                count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_raw_stripe_confidence_regions_df_from_suspected_stripe_regions(result):\n",
    "    col_confidence_interval_width = 8\n",
    "    row_confidence_interval_width = 10\n",
    "    reshaped = np.reshape(result, (result.shape[0] * result.shape[1], result.shape[2]))\n",
    "    df = pd.DataFrame(data=reshaped, columns=[\"has_stripes\", \"col_no\", \"stripe_start\", \"stripe_end\", \"no_of_stripes\", \"average_stripe_width\"])\n",
    "    df = df[df[\"has_stripes\"]==1]\n",
    "    df = df[df[\"average_stripe_width\"]>=2]\n",
    "    tidy_df = pd.DataFrame()\n",
    "    tidy_df[\"col_no_original\"] = convert_rot90_col_no_to_original_col_no(np.rot90(img_0), df[\"col_no\"])\n",
    "    tidy_df[\"stripe_centre_for_each_col\"] = (df[\"stripe_start\"] + df[\"stripe_end\"]) / 2\n",
    "\n",
    "    tidy_df[\"col_confidence_interval_start\"] = tidy_df[\"col_no_original\"] - df[\"average_stripe_width\"] * col_confidence_interval_width / 2\n",
    "    tidy_df[\"col_confidence_interval_start\"] = np.where(tidy_df[\"col_confidence_interval_start\"]< 0, 0, tidy_df[\"col_confidence_interval_start\"]) \n",
    "\n",
    "    tidy_df[\"col_confidence_interval_end\"] = tidy_df[\"col_no_original\"] + df[\"average_stripe_width\"] * col_confidence_interval_width / 2\n",
    "    tidy_df[\"col_confidence_interval_end\"] = np.where(tidy_df[\"col_confidence_interval_end\"]>img_0.shape[1]-1, img_0.shape[1]-1, tidy_df[\"col_confidence_interval_end\"]) \n",
    "\n",
    "    tidy_df[\"row_confidence_interval_start\"] = tidy_df[\"stripe_centre_for_each_col\"] - df[\"average_stripe_width\"] * row_confidence_interval_width / 2\n",
    "    tidy_df[\"row_confidence_interval_start\"] = np.where(tidy_df[\"row_confidence_interval_start\"]< 0, 0, tidy_df[\"row_confidence_interval_start\"]) \n",
    "\n",
    "    tidy_df[\"row_confidence_interval_end\"] = tidy_df[\"stripe_centre_for_each_col\"] + df[\"average_stripe_width\"] * row_confidence_interval_width / 2\n",
    "    tidy_df[\"row_confidence_interval_end\"] = np.where(tidy_df[\"row_confidence_interval_end\"]>img_0.shape[0]-1, img_0.shape[0]-1, tidy_df[\"row_confidence_interval_end\"]) \n",
    "    \n",
    "    return tidy_df\n",
    "\n",
    "def get_combined_stripe_confidence_regions_df_from_raw_stripe_confidence_regions_df(raw_df, combine_threshold=0.2):\n",
    "    return combine_to_region(raw_df, combine_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_rectangles_from_stripe_region_df(df, img, img_name):\n",
    "    df_for_rectangles = df[['row_confidence_interval_start', 'col_confidence_interval_start', 'row_confidence_interval_end', 'col_confidence_interval_end']]\n",
    "    rectangles = df_for_rectangles[:].to_numpy().astype(int)\n",
    "    img_copy = np.copy(img)\n",
    "    count = 0\n",
    "    for rect in rectangles:\n",
    "        cv2.rectangle(img_copy, (rect[1], rect[0]), (rect[3], rect[2]), color=(0, 255, 0), thickness=16)\n",
    "        count += 1\n",
    "        \n",
    "    img_full_name = img_name + \"_\" + str(count) + \".jpeg\"\n",
    "    cv2.imwrite(os.path.join(img_save_dir, img_full_name), img_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "range_square_save_dir = 'D:\\\\1920Sem1\\\\CS4243\\\\project_wx_tryout_code\\\\range_square'\n",
    "range_save_dir = 'D:\\\\1920Sem1\\\\CS4243\\\\project_wx_tryout_code\\\\range'\n",
    "\n",
    "def match_wanda_face(template_original, range_to_match, kernel_size, range_name):\n",
    "    template = cv2.resize(template_original, (kernel_size, kernel_size))\n",
    "    \n",
    "    w, h = template.shape[::-1]\n",
    "    res = cv2.matchTemplate(range_to_match, template, cv2.TM_CCOEFF_NORMED)\n",
    "    res_max_value = res[np.unravel_index(np.argmax(res, axis=None), res.shape)]\n",
    "#     print(kernel_size)\n",
    "#     print(range_name + \": \" + str(res_max_value))\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "    top_left = max_loc\n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "    \n",
    "    range_to_match_copy = range_to_match.copy()\n",
    "    \n",
    "    square_cropped = range_to_match_copy[top_left[1]:top_left[1] + h , top_left[0]:top_left[0] + w ]\n",
    "    imgsquare_name = \"square\" + \"_\" + range_name + \"_\" + str(int(res_max_value*100)) + \".png\"\n",
    "    cv2.imwrite(os.path.join(range_square_save_dir, imgsquare_name), square_cropped)\n",
    "\n",
    "#     cv2.rectangle(range_to_match_copy,top_left, bottom_right, 255, 2)   \n",
    "    imgname = range_name + \"_\" + str(int(res_max_value*100)) + \".png\"\n",
    "    cv2.imwrite(os.path.join(range_save_dir, imgname), range_to_match_copy)\n",
    "    \n",
    "#     print(square_cropped.shape)\n",
    "    return square_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_files_in_dir(dir):\n",
    "    return [os.path.join(dir, img) for img in os.listdir(dir) if os.path.isfile(os.path.join(dir, img))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "range_square_save_dir = 'D:\\\\1920Sem1\\\\CS4243\\\\project_wx_tryout_code\\\\range_square'\n",
    "range_save_dir = 'D:\\\\1920Sem1\\\\CS4243\\\\project_wx_tryout_code\\\\range'\n",
    "\n",
    "template_wenda_dir = 'D:\\\\1920Sem1\\\\CS4243\\\\project_wx_tryout_code\\\\range_square\\\\wenda'\n",
    "def match_wanda_face_dir(template_original_dir, range_to_match, kernel_size, range_name):\n",
    "    template_originals = all_files_in_dir(template_original_dir)[:3]\n",
    "    \n",
    "    range_to_match_copy = range_to_match.copy()\n",
    "    range_to_match_clean = range_to_match.copy()\n",
    "    \n",
    "    bboxes = []\n",
    "    squares_cropped = []\n",
    "    res_values = []\n",
    "    for template_original_address in template_originals:\n",
    "        template_original = cv2.imread(template_original_address, 0)\n",
    "        w = template_original.shape[0]\n",
    "        \n",
    "        template = cv2.resize(template_original, (kernel_size, kernel_size))\n",
    "\n",
    "        w, h = template.shape[::-1]\n",
    "        res = cv2.matchTemplate(range_to_match, template, cv2.TM_CCOEFF_NORMED)\n",
    "        res_max_value = res[np.unravel_index(np.argmax(res, axis=None), res.shape)]\n",
    "    #     print(kernel_size)\n",
    "    #     print(range_name + \": \" + str(res_max_value))\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "        top_left = max_loc\n",
    "        bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "        \n",
    "        bbox = (top_left[0], top_left[1], w, h)\n",
    "        bboxes.append(bbox)\n",
    "        \n",
    "        square_cropped = range_to_match_clean[top_left[1]:top_left[1] + h , top_left[0]:top_left[0] + w ]\n",
    "        squares_cropped.append(square_cropped)\n",
    "        res_values.append(res_max_value)\n",
    "\n",
    "        cv2.rectangle(range_to_match_copy,top_left, bottom_right, 255, 2)   \n",
    "    \n",
    "    iou_3 = IoU_3(bboxes[0], bboxes[1], bboxes[2])\n",
    "    \n",
    "    if (iou_3 > -0.2):\n",
    "#         ind = res_values.index(max(res_values))\n",
    "        for k in range(3):\n",
    "            square_cropped = squares_cropped[k]\n",
    "            imgsquare_name = \"square\" + str(k) + \"_\" + range_name + \"_\" + str(int(res_max_value*100)) + \".png\"\n",
    "            cv2.imwrite(os.path.join(range_square_save_dir, imgsquare_name), square_cropped)\n",
    "        \n",
    "        imgname = range_name + \"_\" + str(int(res_max_value*100)) + \".png\"\n",
    "        cv2.imwrite(os.path.join(range_save_dir, imgname), range_to_match_copy)\n",
    "\n",
    "    #     print(square_cropped.shape)\n",
    "#         return square_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def IoU_3(bbox1, bbox2, bbox3):\n",
    "    \"\"\" Compute IoU of two bounding boxes\n",
    "\n",
    "    Args:\n",
    "        bbox1 - 4-tuple (x, y, w, h) where (x, y) is the top left corner of\n",
    "            the bounding box, and (w, h) are width and height of the box.\n",
    "        bbox2 - 4-tuple (x, y, w, h) where (x, y) is the top left corner of\n",
    "            the bounding box, and (w, h) are width and height of the box.\n",
    "        bbox3 - 4-tuple (x, y, w, h) where (x, y) is the top left corner of\n",
    "            the bounding box, and (w, h) are width and height of the box.\n",
    "    Returns:\n",
    "        score - IoU score\n",
    "    \"\"\"\n",
    "    x1, y1, w1, h1 = bbox1\n",
    "    x2, y2, w2, h2 = bbox2\n",
    "    x3, y3, w3, h3 = bbox3\n",
    "    score = 0\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    y1y2_x_left = max(x1, x2)\n",
    "    y1y2_y_top = max(y1, y2)\n",
    "    y1y2_x_right = min(x1+w1, x2+w2)\n",
    "    y1y2_y_bottom = min(y1+h1, y2+h2)\n",
    "    \n",
    "    if y1y2_x_right < y1y2_x_left or y1y2_y_bottom < y1y2_y_top:\n",
    "        return 0.0\n",
    "    \n",
    "    y1y3_x_left = max(x1, x3)\n",
    "    y1y3_y_top = max(y1, y3)\n",
    "    y1y3_x_right = min(x1+w1, x3+w3)\n",
    "    y1y3_y_bottom = min(y1+h1, y3+h3)\n",
    "    \n",
    "    if y1y3_x_right < y1y3_x_left or y1y3_y_bottom < y1y3_y_top:\n",
    "        return 0.0\n",
    "    \n",
    "    y3y2_x_left = max(x3, x2)\n",
    "    y3y2_y_top = max(y3, y2)\n",
    "    y3y2_x_right = min(x3+w3, x2+w2)\n",
    "    y3y2_y_bottom = min(y3+h3, y2+h2)\n",
    "\n",
    "    if y3y2_x_right < y3y2_x_left or y3y2_y_bottom < y3y2_y_top:\n",
    "        return 0.0\n",
    "  \n",
    "    y1y2y3_x_left = max(x1, x2, y3)\n",
    "    y1y2y3_y_top = max(y1, y2, y3)\n",
    "    y1y2y3_x_right = min(x1+w1, x2+w2, x3+w3)\n",
    "    y1y2y3_y_bottom = min(y1+h1, y2+h2, y3+h3)\n",
    "\n",
    "    if y1y2y3_x_right < y1y2y3_x_left or y1y2y3_y_bottom < y1y2y3_y_top:\n",
    "        return 0.0\n",
    "    \n",
    "    y1y2_intersection_area = (y1y2_x_right - y1y2_x_left) * (y1y2_y_bottom - y1y2_y_top)\n",
    "    y1y3_intersection_area = (y1y3_x_right - y1y3_x_left) * (y1y3_y_bottom - y1y3_y_top)\n",
    "    y3y2_intersection_area = (y3y2_x_right - y3y2_x_left) * (y3y2_y_bottom - y3y2_y_top)\n",
    "\n",
    "    y1y2y3_intersection_area = (y1y2y3_x_right - y1y2y3_x_left) * (y1y2y3_y_bottom - y1y2y3_y_top)\n",
    "    \n",
    "    y1_area1 = w1 * h1\n",
    "    y2_area2 = w2 * h2\n",
    "    y3_area3 = w3 * h3\n",
    "\n",
    "    total_area = float(y1_area1 + y2_area2 + y3_area3 - y1y2_intersection_area - y1y3_intersection_area - y3y2_intersection_area + y1y2y3_intersection_area)\n",
    "    score = y1y2y3_intersection_area / total_area\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_suspected_waldo_stripe_region_for_img(img):\n",
    "\n",
    "    red_white_mask_rot = preprocess_input_img(img)\n",
    "\n",
    "    start_time = time.time()\n",
    "    result  = np.apply_along_axis(get_suspected_waldo_stripe_region_for_col, 1, red_white_mask_rot)\n",
    "    stop_time = time.time()\n",
    "    print(\"--- %s seconds ---\" % (stop_time - start_time))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 68:\n",
      "--- 75.94212007522583 seconds ---\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(images)-2, len(images)-1):\n",
    "    print(\"image \" + str(i) + \":\") \n",
    "\n",
    "    img_0 = cv2.imread(images[i])\n",
    "\n",
    "    result = get_suspected_waldo_stripe_region_for_img(img_0)\n",
    "    raw_stripe_confidence_regions_df = get_raw_stripe_confidence_regions_df_from_suspected_stripe_regions(result)\n",
    "    combined_stripe_confidence_regions_df = get_combined_stripe_confidence_regions_df_from_raw_stripe_confidence_regions_df(raw_stripe_confidence_regions_df)\n",
    "\n",
    "    draw_rectangles_from_stripe_region_df(combined_stripe_confidence_regions_df, img_0, \"img_\"+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "\n",
    "def hog_d(grey_images_address):\n",
    "    hog_desc = []\n",
    "    for img_address in grey_images_address:\n",
    "        img = cv2.imread(img_address, 0)\n",
    "        img = cv2.resize(img, (200,200))\n",
    "        fd = hog(img, orientations=8, pixels_per_cell=(8, 8),\n",
    "                          cells_per_block=(int(img.shape[0]/100), int(img.shape[1]/100)),\n",
    "                 transform_sqrt=True, block_norm=\"L1\")\n",
    "        hog_desc.append(fd)\n",
    "\n",
    "    return hog_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_images_address = [os.path.join(range_square_save_dir, img) for img in os.listdir(range_square_save_dir) if os.path.isfile(os.path.join(range_square_save_dir, img))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hog_d_test_imgs = hog_d(test_images_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('clf_hog_waldo_wenda.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "    predictions = clf.predict(hog_d_test_imgs)\n",
    "    indices_waldo = np.where(np.array(predictions)==1)\n",
    "    print(indices_waldo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 81.25963521003723 seconds ---\n",
      "--- 0.4190378189086914 seconds ---\n",
      "(57, 7)\n"
     ]
    }
   ],
   "source": [
    "num = 58\n",
    "img_0 = cv2.imread(images[num])\n",
    "\n",
    "range_save_dir = 'D:\\\\1920Sem1\\\\CS4243\\\\project_wx_tryout_code\\\\range'\n",
    "range_square_save_dir = 'D:\\\\1920Sem1\\\\CS4243\\\\project_wx_tryout_code\\\\range_square'\n",
    "template_wanda = cv2.imread('template_wanda_2.png', 0)\n",
    "\n",
    "red_white_mask_rot = preprocess_input_img(img_0)\n",
    "\n",
    "start_time = time.time()\n",
    "result  = np.apply_along_axis(get_suspected_waldo_stripe_region_for_col, 1, red_white_mask_rot)\n",
    "stop_time = time.time()\n",
    "print(\"--- %s seconds ---\" % (stop_time - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "raw_stripe_confidence_regions_df = get_raw_stripe_confidence_regions_df_from_suspected_stripe_regions(result)\n",
    "combined_stripe_confidence_regions_df = get_combined_stripe_confidence_regions_df_from_raw_stripe_confidence_regions_df(raw_stripe_confidence_regions_df)\n",
    "stop_time = time.time()\n",
    "print(\"--- %s seconds ---\" % (stop_time - start_time))\n",
    "print(combined_stripe_confidence_regions_df[:].to_numpy().shape)\n",
    "\n",
    "df_for_rectangles = combined_stripe_confidence_regions_df.copy()\n",
    "\n",
    "df_for_head = df_for_rectangles[['row_confidence_interval_start', 'col_confidence_interval_start', 'row_confidence_interval_end', 'col_confidence_interval_end']].copy()\n",
    "df_for_head['stripe_width'] = (df_for_head['col_confidence_interval_end'] - df_for_head['col_confidence_interval_start'])/8\n",
    "\n",
    "# to expand the body bbox horizontally a bit and extend the body bbox upwards to bound the head\n",
    "df_for_head['col_confidence_interval_start'] = np.where(df_for_head['col_confidence_interval_start'] - 2*df_for_head['stripe_width']<0, 0, df_for_head['col_confidence_interval_start'] - 2*df_for_head['stripe_width'])\n",
    "df_for_head['col_confidence_interval_end'] = np.where(df_for_head['col_confidence_interval_end'] + 2*df_for_head['stripe_width']>img_0.shape[1]-1, img_0.shape[1]-1, df_for_head['col_confidence_interval_end'] + 2*df_for_head['stripe_width'])\n",
    "df_for_head['row_confidence_interval_start'] = np.where(df_for_head['row_confidence_interval_start'] - 10*df_for_head['stripe_width']<0, 0, df_for_head['row_confidence_interval_start'] - 10*df_for_head['stripe_width'])\n",
    "df_for_head['row_confidence_interval_end'] = np.where(df_for_head['row_confidence_interval_end'] + 1*df_for_head['stripe_width']>img_0.shape[0]-1, img_0.shape[0]-1, df_for_head['row_confidence_interval_end'] + 1*df_for_head['stripe_width'])\n",
    "\n",
    "\n",
    "square_compilations = np.array([[0]])\n",
    "range_data = df_for_head[:].to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(range_data.shape[0]):\n",
    "\n",
    "    wanda_row = tuple(range_data[i].astype(int))\n",
    "    wanda_row_start, wanda_col_start, wanda_row_end, wanda_col_end, wanda_stripe_width = wanda_row\n",
    "\n",
    "    range1 = img_0[wanda_row_start:wanda_row_end, wanda_col_start:wanda_col_end]\n",
    "    range1_gray = cv2.cvtColor(range1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    head_stripe_count = 5\n",
    "    kernel_size = (head_stripe_count*wanda_stripe_width // 2) * 2 + 1\n",
    "    \n",
    "    match_wanda_face_dir(template_wenda_dir, range1_gray, kernel_size, str(num) + \"_range\"+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
